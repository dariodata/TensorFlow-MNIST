{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (42000, 785)\nTest set shape: (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "#X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "train_orig = pd.read_csv('train.csv')\n",
    "test_orig = pd.read_csv('test.csv')\n",
    "print('Train set shape:',  train_orig.shape)\n",
    "print('Test set shape:',  test_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig = train_orig.iloc[:,1:]\n",
    "Y_train_orig = train_orig.iloc[:,0]\n",
    "X_test_orig = test_orig\n",
    "\n",
    "X_train_orig.shape, Y_train_orig.shape, X_test_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33600, 784), (8400, 784), (33600,), (8400,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_orig, Y_train_orig, test_size=0.20, random_state=42)\n",
    "\n",
    "X_train.shape, X_val.shape, Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "X_train = X_train.T/255.\n",
    "X_val = X_val.T/255.\n",
    "X_test = X_test_orig.T/255.\n",
    "# One-hot encode labels\n",
    "Y_train = pd.get_dummies(Y_train).T\n",
    "Y_val = pd.get_dummies(Y_val).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 33600\nnumber of validation examples = 8400\nnumber of test examples = 28000\nX_train shape: (784, 33600)\nX_val shape: (784, 8400)\nY_train shape: (10, 33600)\nY_val shape: (10, 8400)\nX_test shape: (784, 28000)\n"
     ]
    }
   ],
   "source": [
    "print (\"number of training examples = \" + str(X_train.shape[1]))\n",
    "print (\"number of validation examples = \" + str(X_val.shape[1]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[1]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"X_val shape: \" + str(X_val.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"Y_val shape: \" + str(Y_val.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=(n_x, None), name='X')\n",
    "    Y = tf.placeholder(tf.float32, shape=(n_y, None), name='Y')\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow.\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)\n",
    "        \n",
    "    W1 = tf.get_variable('W1', [25, 784], initializer= tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b1 = tf.get_variable('b1', [25,1], initializer= tf.zeros_initializer())\n",
    "    W2 = tf.get_variable('W2', [12,25], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b2 = tf.get_variable('b2', [12,1], initializer= tf.zeros_initializer())\n",
    "    W3 = tf.get_variable('W3', [10,12], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b3 = tf.get_variable('b3', [10,1], initializer= tf.zeros_initializer())\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters, keep_prob):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    Z1 = tf.matmul(W1, X) + b1                    # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                           # A1 = relu(Z1)\n",
    "    A1 = tf.nn.dropout(A1, keep_prob)\n",
    "    Z2 = tf.matmul(W2, A1) + b2                   # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                           # A2 = relu(Z2)\n",
    "    A2 = tf.nn.dropout(A2, keep_prob)\n",
    "    Z3 = tf.matmul(W3, A2) + b3                   # Z3 = np.dot(W3,Z2) + b3\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    \n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "    \n",
    "    params = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3}\n",
    "    \n",
    "    x = tf.placeholder(\"float\", [784, None])\n",
    "    \n",
    "    z3 = forward_propagation_for_predict(x, params)\n",
    "    p = tf.argmax(z3)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    prediction = sess.run(p, feed_dict = {x: X})\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation_for_predict(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3'] \n",
    "                                                           # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 700, minibatch_size = 32, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z3 = forward_propagation(X, parameters, keep_prob)\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y:minibatch_Y, \n",
    "                                                                            keep_prob:0.2})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print(\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print(\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print(\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train, keep_prob:1.0}))\n",
    "        print(\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test, keep_prob:1.0}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 2.348236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 100: 1.806183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 200: 1.785646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 300: 1.760308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 400: 1.755638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 500: 1.752991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 600: 1.745863\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1204cf518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.583125\nTest Accuracy: 0.572143\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train.values, Y_train.values, X_val.values, Y_val.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that I'm overfitting the training set. This means that additional tuning is needed, in particular regularization. I will try to do introduce drop-out to see if the results improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parameters' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b6492f8aa398>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'parameters' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = predict(X_test, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(columns=['ImageId','Label'])\n",
    "submission['ImageId'] = list(range(1, X_test.shape[1]+1))\n",
    "submission['Label'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result from Kaggle was: Your submission scored 0.94157, which is not an improvement of your best score. Keep trying!\n"
     ]
    }
   ],
   "source": [
    "print('Result from Kaggle was: Your submission scored 0.94157, which is not an improvement of your best score. Keep trying!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}